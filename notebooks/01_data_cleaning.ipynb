{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce32aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING DATA CLEANING PROCESS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# üìì 01_data_cleaning.ipynb\n",
    "# Step-by-Step Data Cleaning Process\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üöÄ STARTING DATA CLEANING PROCESS\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39bd5197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ STEP 1: Import and Load Data\n",
      "----------------------------------------\n",
      "‚úÖ Importing libraries: pandas, numpy, datetime\n",
      "üìÅ Loading data from: ../data/Financials.json\n",
      "‚úÖ Successfully loaded data\n",
      "üìä Dataset Shape: (700, 16) (rows, columns)\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>Product</th>\n",
       "      <th>Discount Band</th>\n",
       "      <th>Units Sold</th>\n",
       "      <th>Manufacturing Price</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Gross Sales</th>\n",
       "      <th>Discounts</th>\n",
       "      <th>Sales</th>\n",
       "      <th>COGS</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Date</th>\n",
       "      <th>Month Number</th>\n",
       "      <th>Month Name</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Government</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>$1,618.50</td>\n",
       "      <td>$3.00</td>\n",
       "      <td>$20.00</td>\n",
       "      <td>$32,370.00</td>\n",
       "      <td>$-</td>\n",
       "      <td>$32,370.00</td>\n",
       "      <td>$16,185.00</td>\n",
       "      <td>$16,185.00</td>\n",
       "      <td>01/01/2014</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Government</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>$1,321.00</td>\n",
       "      <td>$3.00</td>\n",
       "      <td>$20.00</td>\n",
       "      <td>$26,420.00</td>\n",
       "      <td>$-</td>\n",
       "      <td>$26,420.00</td>\n",
       "      <td>$13,210.00</td>\n",
       "      <td>$13,210.00</td>\n",
       "      <td>01/01/2014</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Midmarket</td>\n",
       "      <td>France</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>$2,178.00</td>\n",
       "      <td>$3.00</td>\n",
       "      <td>$15.00</td>\n",
       "      <td>$32,670.00</td>\n",
       "      <td>$-</td>\n",
       "      <td>$32,670.00</td>\n",
       "      <td>$21,780.00</td>\n",
       "      <td>$10,890.00</td>\n",
       "      <td>01/06/2014</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Midmarket</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>$888.00</td>\n",
       "      <td>$3.00</td>\n",
       "      <td>$15.00</td>\n",
       "      <td>$13,320.00</td>\n",
       "      <td>$-</td>\n",
       "      <td>$13,320.00</td>\n",
       "      <td>$8,880.00</td>\n",
       "      <td>$4,440.00</td>\n",
       "      <td>01/06/2014</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Midmarket</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>Carretera</td>\n",
       "      <td>None</td>\n",
       "      <td>$2,470.00</td>\n",
       "      <td>$3.00</td>\n",
       "      <td>$15.00</td>\n",
       "      <td>$37,050.00</td>\n",
       "      <td>$-</td>\n",
       "      <td>$37,050.00</td>\n",
       "      <td>$24,700.00</td>\n",
       "      <td>$12,350.00</td>\n",
       "      <td>01/06/2014</td>\n",
       "      <td>6</td>\n",
       "      <td>June</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Segment  Country      Product Discount Band   Units Sold  \\\n",
       "0  Government   Canada   Carretera          None    $1,618.50    \n",
       "1  Government  Germany   Carretera          None    $1,321.00    \n",
       "2   Midmarket   France   Carretera          None    $2,178.00    \n",
       "3   Midmarket  Germany   Carretera          None      $888.00    \n",
       "4   Midmarket   Mexico   Carretera          None    $2,470.00    \n",
       "\n",
       "  Manufacturing Price Sale Price   Gross Sales Discounts         Sales  \\\n",
       "0              $3.00     $20.00    $32,370.00      $-      $32,370.00    \n",
       "1              $3.00     $20.00    $26,420.00      $-      $26,420.00    \n",
       "2              $3.00     $15.00    $32,670.00      $-      $32,670.00    \n",
       "3              $3.00     $15.00    $13,320.00      $-      $13,320.00    \n",
       "4              $3.00     $15.00    $37,050.00      $-      $37,050.00    \n",
       "\n",
       "           COGS        Profit        Date  Month Number Month Name  Year  \n",
       "0   $16,185.00    $16,185.00   01/01/2014             1   January   2014  \n",
       "1   $13,210.00    $13,210.00   01/01/2014             1   January   2014  \n",
       "2   $21,780.00    $10,890.00   01/06/2014             6      June   2014  \n",
       "3    $8,880.00     $4,440.00   01/06/2014             6      June   2014  \n",
       "4   $24,700.00    $12,350.00   01/06/2014             6      June   2014  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Total Records: 700\n",
      "üìä Total Columns: 16\n"
     ]
    }
   ],
   "source": [
    "print(\"üîπ STEP 1: Import and Load Data\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 1.1 Import essential libraries\n",
    "print(\"‚úÖ Importing libraries: pandas, numpy, datetime\")\n",
    "\n",
    "# 1.2 Load dataset\n",
    "data_path = \"../data/Financials.json\"\n",
    "print(f\"üìÅ Loading data from: {data_path}\")\n",
    "\n",
    "try:\n",
    "    with open(data_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"‚úÖ Successfully loaded data\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading data: {e}\")\n",
    "    raise\n",
    "\n",
    "# 1.3 Display first few rows and shape\n",
    "print(f\"üìä Dataset Shape: {df.shape} (rows, columns)\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nüìà Total Records: {len(df)}\")\n",
    "print(f\"üìä Total Columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14023ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ STEP 2: Data Consistency Rules\n",
      "----------------------------------------\n",
      "üîç Starting consistency checks...\n",
      "\n",
      "üìã Checking column: Segment\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Country\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Product\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Discount Band\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Units Sold\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Manufacturing Price\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Sale Price\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Gross Sales\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Discounts\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Sales\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: COGS\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Profit\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Date\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Month Number\n",
      "   Data type: int64\n",
      "   üî¢ Numeric column detected\n",
      "\n",
      "üìã Checking column: Month Name\n",
      "   Data type: object\n",
      "   üìù Categorical column detected\n",
      "\n",
      "üìã Checking column: Year\n",
      "   Data type: int64\n",
      "   üî¢ Numeric column detected\n",
      "\n",
      "============================================================\n",
      "üìä CONSISTENCY CHECK SUMMARY\n",
      "============================================================\n",
      "üìà Total Columns Checked: 16\n",
      "‚úÖ Valid Columns: 16\n",
      "‚ùå Columns with Issues: 0\n",
      "\n",
      "üîç DETAILED ISSUES:\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "üîç DEEP CHECK: Mixed Types in Object Columns\n",
      "============================================================\n",
      "\n",
      "üîç Deep checking: Segment\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Country\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Product\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Discount Band\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Units Sold\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Manufacturing Price\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Sale Price\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Gross Sales\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Discounts\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Sales\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: COGS\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Profit\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Date\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üîç Deep checking: Month Name\n",
      "   ‚úÖ Consistent types: str\n",
      "\n",
      "üéØ CONSISTENCY CHECK COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "print(\"üîπ STEP 2: Data Consistency Rules\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "def check_consistency_rules(df):\n",
    "    \"\"\"\n",
    "    Check data consistency rules for different column types\n",
    "    \"\"\"\n",
    "    consistency_report = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        print(f\"\\nüìã Checking column: {column}\")\n",
    "        print(f\"   Data type: {df[column].dtype}\")\n",
    "        \n",
    "        # Get non-null values for analysis\n",
    "        non_null_values = df[column].dropna()\n",
    "        \n",
    "        if len(non_null_values) == 0:\n",
    "            print(\"   ‚ö†Ô∏è  Column is empty\")\n",
    "            consistency_report[column] = {\"status\": \"empty\", \"issues\": []}\n",
    "            continue\n",
    "            \n",
    "        # Rule 1: Check for numeric columns (float, int)\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            print(\"   üî¢ Numeric column detected\")\n",
    "            \n",
    "            # Check if all values are actually numeric\n",
    "            numeric_issues = []\n",
    "            \n",
    "            # Check for infinite values\n",
    "            infinite_count = np.isinf(df[column]).sum()\n",
    "            if infinite_count > 0:\n",
    "                numeric_issues.append(f\"Contains {infinite_count} infinite values\")\n",
    "                \n",
    "            # Check for extreme outliers (beyond 6 standard deviations)\n",
    "            if len(non_null_values) > 1:\n",
    "                z_scores = np.abs((non_null_values - non_null_values.mean()) / non_null_values.std())\n",
    "                extreme_outliers = (z_scores > 6).sum()\n",
    "                if extreme_outliers > 0:\n",
    "                    numeric_issues.append(f\"Contains {extreme_outliers} extreme outliers\")\n",
    "            \n",
    "            consistency_report[column] = {\n",
    "                \"type\": \"numeric\",\n",
    "                \"status\": \"valid\" if len(numeric_issues) == 0 else \"issues\",\n",
    "                \"issues\": numeric_issues,\n",
    "                \"stats\": {\n",
    "                    \"min\": non_null_values.min(),\n",
    "                    \"max\": non_null_values.max(),\n",
    "                    \"mean\": non_null_values.mean(),\n",
    "                    \"null_count\": df[column].isnull().sum()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        # Rule 2: Check for categorical columns (object)\n",
    "        elif df[column].dtype == 'object':\n",
    "            print(\"   üìù Categorical column detected\")\n",
    "            \n",
    "            categorical_issues = []\n",
    "            \n",
    "            # Check for mixed data types\n",
    "            type_counts = non_null_values.apply(type).value_counts()\n",
    "            if len(type_counts) > 1:\n",
    "                categorical_issues.append(f\"Mixed types: {dict(type_counts)}\")\n",
    "            \n",
    "            # Check for numeric values in categorical columns\n",
    "            numeric_values = pd.to_numeric(non_null_values, errors='coerce')\n",
    "            numeric_count = numeric_values.notna().sum()\n",
    "            if numeric_count > 0:\n",
    "                categorical_issues.append(f\"Contains {numeric_count} numeric values\")\n",
    "            \n",
    "            # Check for inconsistent formatting\n",
    "            # Look for values with special characters that might indicate mixed content\n",
    "            special_char_pattern = r'[0-9]+\\s*[a-zA-Z]+|[a-zA-Z]+\\s*[0-9]+'\n",
    "            mixed_content = non_null_values.astype(str).str.contains(special_char_pattern, na=False).sum()\n",
    "            if mixed_content > 0:\n",
    "                categorical_issues.append(f\"Contains {mixed_content} mixed alphanumeric values\")\n",
    "            \n",
    "            consistency_report[column] = {\n",
    "                \"type\": \"categorical\",\n",
    "                \"status\": \"valid\" if len(categorical_issues) == 0 else \"issues\",\n",
    "                \"issues\": categorical_issues,\n",
    "                \"stats\": {\n",
    "                    \"unique_values\": len(non_null_values.unique()),\n",
    "                    \"most_frequent\": non_null_values.mode().iloc[0] if len(non_null_values.mode()) > 0 else None,\n",
    "                    \"null_count\": df[column].isnull().sum()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        # Rule 3: Check for datetime columns\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "            print(\"   üìÖ Datetime column detected\")\n",
    "            \n",
    "            datetime_issues = []\n",
    "            \n",
    "            # Check for invalid dates\n",
    "            if pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "                # Check for far future/past dates (potential errors)\n",
    "                if len(non_null_values) > 0:\n",
    "                    min_date = non_null_values.min()\n",
    "                    max_date = non_null_values.max()\n",
    "                    \n",
    "                    # Check for unrealistic dates (before 1900 or after 2100)\n",
    "                    if min_date.year < 1900:\n",
    "                        datetime_issues.append(f\"Contains dates before 1900: {min_date}\")\n",
    "                    if max_date.year > 2100:\n",
    "                        datetime_issues.append(f\"Contains dates after 2100: {max_date}\")\n",
    "            \n",
    "            consistency_report[column] = {\n",
    "                \"type\": \"datetime\",\n",
    "                \"status\": \"valid\" if len(datetime_issues) == 0 else \"issues\",\n",
    "                \"issues\": datetime_issues,\n",
    "                \"stats\": {\n",
    "                    \"date_range\": f\"{min_date} to {max_date}\" if len(non_null_values) > 0 else \"N/A\",\n",
    "                    \"null_count\": df[column].isnull().sum()\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        else:\n",
    "            print(f\"   üîç Other data type: {df[column].dtype}\")\n",
    "            consistency_report[column] = {\n",
    "                \"type\": \"other\",\n",
    "                \"status\": \"unknown\",\n",
    "                \"issues\": [\"Unclassified data type\"],\n",
    "                \"stats\": {\"null_count\": df[column].isnull().sum()}\n",
    "            }\n",
    "    \n",
    "    return consistency_report\n",
    "\n",
    "def print_consistency_summary(consistency_report):\n",
    "    \"\"\"\n",
    "    Print a summary of consistency check results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä CONSISTENCY CHECK SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    total_columns = len(consistency_report)\n",
    "    valid_columns = sum(1 for col_report in consistency_report.values() \n",
    "                       if col_report['status'] == 'valid')\n",
    "    issue_columns = sum(1 for col_report in consistency_report.values() \n",
    "                       if col_report['status'] == 'issues')\n",
    "    \n",
    "    print(f\"üìà Total Columns Checked: {total_columns}\")\n",
    "    print(f\"‚úÖ Valid Columns: {valid_columns}\")\n",
    "    print(f\"‚ùå Columns with Issues: {issue_columns}\")\n",
    "    \n",
    "    # Print detailed issues\n",
    "    print(\"\\nüîç DETAILED ISSUES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for column, report in consistency_report.items():\n",
    "        if report['status'] != 'valid' and report['status'] != 'empty':\n",
    "            print(f\"\\nüìã {column} ({report['type']}):\")\n",
    "            for issue in report['issues']:\n",
    "                print(f\"   ‚ö†Ô∏è  {issue}\")\n",
    "            \n",
    "            # Print additional stats\n",
    "            if 'stats' in report:\n",
    "                stats = report['stats']\n",
    "                if 'null_count' in stats and stats['null_count'] > 0:\n",
    "                    print(f\"   üìä Null values: {stats['null_count']}\")\n",
    "\n",
    "# Run consistency check\n",
    "print(\"üîç Starting consistency checks...\")\n",
    "consistency_report = check_consistency_rules(df)\n",
    "\n",
    "# Print summary\n",
    "print_consistency_summary(consistency_report)\n",
    "\n",
    "# Additional: Check for mixed types in object columns\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç DEEP CHECK: Mixed Types in Object Columns\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def check_mixed_types_deep(df):\n",
    "    \"\"\"Deep check for mixed types in object columns\"\"\"\n",
    "    object_columns = df.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    for column in object_columns:\n",
    "        print(f\"\\nüîç Deep checking: {column}\")\n",
    "        \n",
    "        # Sample non-null values to check types\n",
    "        sample_values = df[column].dropna().head(10)\n",
    "        \n",
    "        if len(sample_values) == 0:\n",
    "            print(\"   ‚úÖ No data to check\")\n",
    "            continue\n",
    "            \n",
    "        # Check actual Python types\n",
    "        type_dict = {}\n",
    "        for val in sample_values:\n",
    "            val_type = type(val).__name__\n",
    "            type_dict[val_type] = type_dict.get(val_type, 0) + 1\n",
    "        \n",
    "        if len(type_dict) > 1:\n",
    "            print(f\"   ‚ùå MIXED TYPES FOUND: {type_dict}\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Consistent types: {list(type_dict.keys())[0]}\")\n",
    "\n",
    "check_mixed_types_deep(df)\n",
    "\n",
    "print(\"\\nüéØ CONSISTENCY CHECK COMPLETED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4a9eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 2: Inspect and Understand Dataset\n",
      "----------------------------------------\n",
      "üìã Column Names and Data Types:\n",
      "Segment                object\n",
      "Country                object\n",
      "Product                object\n",
      "Discount Band          object\n",
      "Units Sold             object\n",
      "Manufacturing Price    object\n",
      "Sale Price             object\n",
      "Gross Sales            object\n",
      "Discounts              object\n",
      "Sales                  object\n",
      "COGS                   object\n",
      "Profit                 object\n",
      "Date                   object\n",
      "Month Number            int64\n",
      "Month Name             object\n",
      "Year                    int64\n",
      "dtype: object\n",
      "\n",
      "üî¢ Numeric Columns: ['Month Number', 'Year']\n",
      "üè∑Ô∏è Object Columns: ['Segment', 'Country', 'Product', 'Discount Band', 'Units Sold', 'Manufacturing Price', 'Sale Price', 'Gross Sales', 'Discounts', 'Sales', 'COGS', 'Profit', 'Date', 'Month Name']\n",
      "\n",
      "üîç Missing Values Check:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Count, Missing Percentage]\n",
      "Index: []\n",
      "‚úÖ No missing values found!\n",
      "\n",
      "üìä Summary Statistics for Numeric Columns:\n",
      "       Month Number         Year\n",
      "count    700.000000   700.000000\n",
      "mean       7.900000  2013.750000\n",
      "std        3.377321     0.433322\n",
      "min        1.000000  2013.000000\n",
      "25%        5.750000  2013.750000\n",
      "50%        9.000000  2014.000000\n",
      "75%       10.250000  2014.000000\n",
      "max       12.000000  2014.000000\n",
      "\n",
      "üè∑Ô∏è Categorical Columns Info:\n",
      "Segment: 5 unique values\n",
      "   Samples: ['Government' 'Midmarket' 'Channel Partners' 'Enterprise' 'Small Business']\n",
      "Country: 5 unique values\n",
      "   Samples: ['Canada' 'Germany' 'France' 'Mexico' 'United States of America']\n",
      "Product: 6 unique values\n",
      "   Samples: [' Carretera ' ' Montana ' ' Paseo ' ' Velo ' ' VTT ']\n",
      "Discount Band: 4 unique values\n",
      "   Samples: [' None ' ' Low ' ' Medium ' ' High ']\n",
      "Units Sold: 510 unique values\n",
      "   Samples: [' $1,618.50 ' ' $1,321.00 ' ' $2,178.00 ' ' $888.00 ' ' $2,470.00 ']\n",
      "Manufacturing Price: 6 unique values\n",
      "   Samples: [' $3.00 ' ' $5.00 ' ' $10.00 ' ' $120.00 ' ' $250.00 ']\n",
      "Sale Price: 7 unique values\n",
      "   Samples: [' $20.00 ' ' $15.00 ' ' $350.00 ' ' $12.00 ' ' $125.00 ']\n",
      "Gross Sales: 550 unique values\n",
      "   Samples: [' $32,370.00 ' ' $26,420.00 ' ' $32,670.00 ' ' $13,320.00 '\n",
      " ' $37,050.00 ']\n",
      "Discounts: 515 unique values\n",
      "   Samples: [' $-   ' ' $276.15 ' ' $344.40 ' ' $72.10 ' ' $44.73 ']\n",
      "Sales: 559 unique values\n",
      "   Samples: [' $32,370.00 ' ' $26,420.00 ' ' $32,670.00 ' ' $13,320.00 '\n",
      " ' $37,050.00 ']\n",
      "COGS: 545 unique values\n",
      "   Samples: [' $16,185.00 ' ' $13,210.00 ' ' $21,780.00 ' ' $8,880.00 ' ' $24,700.00 ']\n",
      "Profit: 557 unique values\n",
      "   Samples: [' $16,185.00 ' ' $13,210.00 ' ' $10,890.00 ' ' $4,440.00 ' ' $12,350.00 ']\n",
      "Month Name: 12 unique values\n",
      "   Samples: [' January ' ' June ' ' December ' ' March ' ' July ']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 2: Inspect and Understand Dataset\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 2.1 Print column names and data types\n",
    "print(\"üìã Column Names and Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# 2.2 Identify column types\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "object_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nüî¢ Numeric Columns: {numeric_cols}\")\n",
    "print(f\"üè∑Ô∏è Object Columns: {object_cols}\")\n",
    "\n",
    "# 2.3 Check for null or missing values\n",
    "print(\"\\nüîç Missing Values Check:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent\n",
    "})\n",
    "print(missing_info[missing_info['Missing Count'] > 0])\n",
    "\n",
    "if missing_info['Missing Count'].sum() == 0:\n",
    "    print(\"‚úÖ No missing values found!\")\n",
    "\n",
    "# 2.4 Review summary statistics\n",
    "print(\"\\nüìä Summary Statistics for Numeric Columns:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Additional info about categorical data\n",
    "print(\"\\nüè∑Ô∏è Categorical Columns Info:\")\n",
    "for col in object_cols:\n",
    "    if col != 'Date':  # Exclude date column for now\n",
    "        print(f\"{col}: {df[col].nunique()} unique values\")\n",
    "        print(f\"   Samples: {df[col].unique()[:5]}\")  # Show first 5 unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3356970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 3: Clean Column Names\n",
      "----------------------------------------\n",
      "üìù Original column names:\n",
      "['Segment', 'Country', 'Product', 'Discount Band', 'Units Sold', 'Manufacturing Price', 'Sale Price', 'Gross Sales', 'Discounts', 'Sales', 'COGS', 'Profit', 'Date', 'Month Number', 'Month Name', 'Year']\n",
      "‚úÖ Cleaned column names:\n",
      "['Segment', 'Country', 'Product', 'Discount_Band', 'Units_Sold', 'Manufacturing_Price', 'Sale_Price', 'Gross_Sales', 'Discounts', 'Sales', 'COGS', 'Profit', 'Date', 'Month_Number', 'Month_Name', 'Year']\n",
      "\n",
      "üìä Columns renamed: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 3: Clean Column Names\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df_clean = df.copy()\n",
    "\n",
    "print(\"üìù Original column names:\")\n",
    "print(list(df_clean.columns))\n",
    "\n",
    "# 3.1 Rename columns for consistency\n",
    "column_mapping = {\n",
    "    'Discount Band': 'Discount_Band',\n",
    "    'Units Sold': 'Units_Sold',\n",
    "    'Manufacturing Price': 'Manufacturing_Price',\n",
    "    'Sale Price': 'Sale_Price',\n",
    "    'Gross Sales': 'Gross_Sales',\n",
    "    'Month Number': 'Month_Number',\n",
    "    'Month Name': 'Month_Name'\n",
    "}\n",
    "\n",
    "df_clean.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "print(\"‚úÖ Cleaned column names:\")\n",
    "print(list(df_clean.columns))\n",
    "\n",
    "# Verify changes\n",
    "print(f\"\\nüìä Columns renamed: {len(column_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d052b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 4: Clean Financial Values\n",
      "----------------------------------------\n",
      "üí∞ Cleaning currency columns:\n",
      "   Cleaning Units_Sold...\n",
      "     Before:  $1,618.50  ‚Üí After: 1618.5\n",
      "   Cleaning Manufacturing_Price...\n",
      "     Before:  $3.00  ‚Üí After: 3.0\n",
      "   Cleaning Sale_Price...\n",
      "     Before:  $20.00  ‚Üí After: 20.0\n",
      "   Cleaning Gross_Sales...\n",
      "     Before:  $32,370.00  ‚Üí After: 32370.0\n",
      "   Cleaning Discounts...\n",
      "     Before:  $-    ‚Üí After: nan\n",
      "   Cleaning Sales...\n",
      "     Before:  $32,370.00  ‚Üí After: 32370.0\n",
      "   Cleaning COGS...\n",
      "     Before:  $16,185.00  ‚Üí After: 16185.0\n",
      "   Cleaning Profit...\n",
      "     Before:  $16,185.00  ‚Üí After: 16185.0\n",
      "‚úÖ All currency columns cleaned and converted to numeric\n",
      "\n",
      "üìä Data types after cleaning:\n",
      "Units_Sold             float64\n",
      "Manufacturing_Price    float64\n",
      "Sale_Price             float64\n",
      "Gross_Sales            float64\n",
      "Discounts              float64\n",
      "Sales                  float64\n",
      "COGS                   float64\n",
      "Profit                 float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 4: Clean Financial Values\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 4.1 Define currency columns to clean\n",
    "currency_columns = [\n",
    "    'Units_Sold', 'Manufacturing_Price', 'Sale_Price', \n",
    "    'Gross_Sales', 'Discounts', 'Sales', 'COGS', 'Profit'\n",
    "]\n",
    "\n",
    "print(\"üí∞ Cleaning currency columns:\")\n",
    "\n",
    "def clean_currency_value(value):\n",
    "    \"\"\"Clean individual currency values\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        # Remove $, commas, spaces, and handle negative values\n",
    "        cleaned = value.replace('$', '').replace(',', '').replace(' ', '')\n",
    "        cleaned = cleaned.replace('$-', '-')  # Handle negative format\n",
    "        return cleaned\n",
    "    return value\n",
    "\n",
    "# 4.2 Clean each currency column\n",
    "for col in currency_columns:\n",
    "    if col in df_clean.columns:\n",
    "        print(f\"   Cleaning {col}...\")\n",
    "        \n",
    "        # Before cleaning\n",
    "        sample_before = df_clean[col].iloc[0] if len(df_clean) > 0 else \"N/A\"\n",
    "        \n",
    "        # Apply cleaning\n",
    "        df_clean[col] = df_clean[col].apply(clean_currency_value)\n",
    "        df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "        \n",
    "        # After cleaning\n",
    "        sample_after = df_clean[col].iloc[0] if len(df_clean) > 0 else \"N/A\"\n",
    "        \n",
    "        print(f\"     Before: {sample_before} ‚Üí After: {sample_after}\")\n",
    "\n",
    "print(\"‚úÖ All currency columns cleaned and converted to numeric\")\n",
    "\n",
    "# 4.3 Verify numeric conversion\n",
    "print(\"\\nüìä Data types after cleaning:\")\n",
    "print(df_clean[currency_columns].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b861ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 5: Handle Missing or Invalid Data\n",
      "----------------------------------------\n",
      "üîç Checking for missing values after cleaning...\n",
      "‚úÖ No missing values found after cleaning!\n",
      "\n",
      "üîé Checking for invalid values...\n",
      "   ‚úÖ Units_Sold: No negative values\n",
      "   ‚úÖ Gross_Sales: No negative values\n",
      "   ‚úÖ Profit: No negative values\n",
      "\n",
      "üéØ Final missing values count: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 5: Handle Missing or Invalid Data\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 5.1 Check for missing values after cleaning\n",
    "print(\"üîç Checking for missing values after cleaning...\")\n",
    "missing_after_clean = df_clean.isnull().sum()\n",
    "\n",
    "if missing_after_clean.sum() > 0:\n",
    "    print(\"‚ö†Ô∏è Missing values found after cleaning:\")\n",
    "    missing_cols = missing_after_clean[missing_after_clean > 0]\n",
    "    for col, count in missing_cols.items():\n",
    "        print(f\"   {col}: {count} missing values ({count/len(df_clean)*100:.2f}%)\")\n",
    "    \n",
    "    # 5.2 Handle missing values\n",
    "    print(\"\\nüõ†Ô∏è Handling missing values...\")\n",
    "    \n",
    "    # For numeric columns, fill with 0 or median\n",
    "    for col in currency_columns:\n",
    "        if col in df_clean.columns and df_clean[col].isnull().sum() > 0:\n",
    "            fill_value = 0  # or df_clean[col].median() for more robust filling\n",
    "            df_clean[col].fillna(fill_value, inplace=True)\n",
    "            print(f\"   Filled {col} with {fill_value}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚úÖ No missing values found after cleaning!\")\n",
    "\n",
    "# 5.3 Check for invalid values (e.g., negative units sold)\n",
    "print(\"\\nüîé Checking for invalid values...\")\n",
    "for col in ['Units_Sold', 'Gross_Sales', 'Profit']:\n",
    "    if col in df_clean.columns:\n",
    "        negative_count = (df_clean[col] < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"   ‚ö†Ô∏è {col}: {negative_count} negative values\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ {col}: No negative values\")\n",
    "\n",
    "# 5.4 Final missing values check\n",
    "final_missing = df_clean.isnull().sum().sum()\n",
    "print(f\"\\nüéØ Final missing values count: {final_missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0124b778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 6: Format Date Columns\n",
      "----------------------------------------\n",
      "üìÖ Converting Date column to datetime...\n",
      "‚úÖ Date range: 2013-01-09 00:00:00 to 2014-01-12 00:00:00\n",
      "\n",
      "üîç Verifying date consistency...\n",
      "üìä Year consistency check: 0 mismatched records\n",
      "\n",
      "üìà Sorting dataset by date...\n",
      "‚úÖ Dataset sorted chronologically\n",
      "üìÖ Final date range: 2013-01-09 00:00:00 to 2014-01-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 6: Format Date Columns\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 6.1 Convert Date column to datetime\n",
    "print(\"üìÖ Converting Date column to datetime...\")\n",
    "\n",
    "if 'Date' in df_clean.columns:\n",
    "    df_clean['Date'] = pd.to_datetime(df_clean['Date'], format='%m/%d/%Y', errors='coerce')\n",
    "    \n",
    "    # Check for invalid dates\n",
    "    invalid_dates = df_clean['Date'].isnull().sum()\n",
    "    if invalid_dates > 0:\n",
    "        print(f\"‚ö†Ô∏è {invalid_dates} invalid dates found and set to NaT\")\n",
    "    \n",
    "    print(f\"‚úÖ Date range: {df_clean['Date'].min()} to {df_clean['Date'].max()}\")\n",
    "\n",
    "# 6.2 Ensure Year, Month_Number, Month_Name are consistent\n",
    "print(\"\\nüîç Verifying date consistency...\")\n",
    "\n",
    "if 'Year' in df_clean.columns and 'Date' in df_clean.columns:\n",
    "    # Extract year from Date and compare with existing Year column\n",
    "    df_clean['Year_From_Date'] = df_clean['Date'].dt.year\n",
    "    \n",
    "    mismatched_years = (df_clean['Year'] != df_clean['Year_From_Date']).sum()\n",
    "    print(f\"üìä Year consistency check: {mismatched_years} mismatched records\")\n",
    "    \n",
    "    # Use the Year from Date column as it's more reliable\n",
    "    df_clean['Year'] = df_clean['Year_From_Date']\n",
    "    df_clean.drop('Year_From_Date', axis=1, inplace=True)\n",
    "\n",
    "# 6.3 Sort dataset chronologically\n",
    "print(\"\\nüìà Sorting dataset by date...\")\n",
    "df_clean.sort_values('Date', inplace=True)\n",
    "df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"‚úÖ Dataset sorted chronologically\")\n",
    "print(f\"üìÖ Final date range: {df_clean['Date'].min()} to {df_clean['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21922995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 7: Feature Engineering\n",
      "----------------------------------------\n",
      "üéØ Creating new KPIs for analysis...\n",
      "‚úÖ Created Profit_Margin: 28.46% average\n",
      "‚úÖ Created Cost_Ratio: 72.10% average\n",
      "‚úÖ Created Revenue_per_Unit: $109.80 average\n",
      "‚úÖ Created Discount_Percentage: 7.33% average\n",
      "\n",
      "üìä New columns created: ['Discount_Band', 'Units_Sold', 'Manufacturing_Price', 'Sale_Price', 'Gross_Sales', 'Month_Number', 'Month_Name', 'Profit_Margin', 'Cost_Ratio', 'Revenue_per_Unit', 'Discount_Percentage']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 7: Feature Engineering\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"üéØ Creating new KPIs for analysis...\")\n",
    "\n",
    "# 7.1 Profit Margin\n",
    "if 'Profit' in df_clean.columns and 'Sales' in df_clean.columns:\n",
    "    df_clean['Profit_Margin'] = (df_clean['Profit'] / df_clean['Sales']) * 100\n",
    "    print(f\"‚úÖ Created Profit_Margin: {df_clean['Profit_Margin'].mean():.2f}% average\")\n",
    "\n",
    "# 7.2 Cost Ratio\n",
    "if 'COGS' in df_clean.columns and 'Sales' in df_clean.columns:\n",
    "    df_clean['Cost_Ratio'] = (df_clean['COGS'] / df_clean['Sales']) * 100\n",
    "    print(f\"‚úÖ Created Cost_Ratio: {df_clean['Cost_Ratio'].mean():.2f}% average\")\n",
    "\n",
    "# 7.3 Revenue per Unit\n",
    "if 'Sales' in df_clean.columns and 'Units_Sold' in df_clean.columns:\n",
    "    df_clean['Revenue_per_Unit'] = df_clean['Sales'] / df_clean['Units_Sold']\n",
    "    print(f\"‚úÖ Created Revenue_per_Unit: ${df_clean['Revenue_per_Unit'].mean():.2f} average\")\n",
    "\n",
    "# 7.4 Discount Percentage (if applicable)\n",
    "if 'Discounts' in df_clean.columns and 'Gross_Sales' in df_clean.columns:\n",
    "    df_clean['Discount_Percentage'] = (df_clean['Discounts'] / df_clean['Gross_Sales']) * 100\n",
    "    print(f\"‚úÖ Created Discount_Percentage: {df_clean['Discount_Percentage'].mean():.2f}% average\")\n",
    "\n",
    "print(f\"\\nüìä New columns created: {[col for col in df_clean.columns if col not in df.columns]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ffdd18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 8: Validate Data Quality\n",
      "----------------------------------------\n",
      "üîç Running final data quality checks...\n",
      "\n",
      "üìã Final Data Types:\n",
      "Segment                        object\n",
      "Country                        object\n",
      "Product                        object\n",
      "Discount_Band                  object\n",
      "Units_Sold                    float64\n",
      "Manufacturing_Price           float64\n",
      "Sale_Price                    float64\n",
      "Gross_Sales                   float64\n",
      "Discounts                     float64\n",
      "Sales                         float64\n",
      "COGS                          float64\n",
      "Profit                        float64\n",
      "Date                   datetime64[ns]\n",
      "Month_Number                    int64\n",
      "Month_Name                     object\n",
      "Year                            int32\n",
      "Profit_Margin                 float64\n",
      "Cost_Ratio                    float64\n",
      "Revenue_per_Unit              float64\n",
      "Discount_Percentage           float64\n",
      "dtype: object\n",
      "\n",
      "üîç Duplicate rows: 0\n",
      "\n",
      "‚úÖ Logical Consistency Checks:\n",
      "   Profit consistency: Average difference = $1110.46\n",
      "   Sales > COGS: 91.0% of records\n",
      "\n",
      "üéØ Final missing values: 0\n",
      "‚úÖ Data quality validation PASSED\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 8: Validate Data Quality\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"üîç Running final data quality checks...\")\n",
    "\n",
    "# 8.1 Recheck data types\n",
    "print(\"\\nüìã Final Data Types:\")\n",
    "print(df_clean.dtypes)\n",
    "\n",
    "# 8.2 Check for duplicates\n",
    "duplicates = df_clean.duplicated().sum()\n",
    "print(f\"\\nüîç Duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"‚ö†Ô∏è Removing duplicate rows...\")\n",
    "    df_clean = df_clean.drop_duplicates()\n",
    "    print(f\"‚úÖ Removed {duplicates} duplicates\")\n",
    "\n",
    "# 8.3 Verify logical consistency\n",
    "print(\"\\n‚úÖ Logical Consistency Checks:\")\n",
    "\n",
    "# Profit ‚âà Sales - COGS\n",
    "if all(col in df_clean.columns for col in ['Profit', 'Sales', 'COGS']):\n",
    "    calculated_profit = df_clean['Sales'] - df_clean['COGS']\n",
    "    profit_diff = (df_clean['Profit'] - calculated_profit).abs().mean()\n",
    "    print(f\"   Profit consistency: Average difference = ${profit_diff:.2f}\")\n",
    "\n",
    "# Sales > COGS (in most cases)\n",
    "sales_greater = (df_clean['Sales'] > df_clean['COGS']).sum()\n",
    "sales_ratio = sales_greater / len(df_clean) * 100\n",
    "print(f\"   Sales > COGS: {sales_ratio:.1f}% of records\")\n",
    "\n",
    "# 8.4 Final missing values check\n",
    "final_missing = df_clean.isnull().sum().sum()\n",
    "print(f\"\\nüéØ Final missing values: {final_missing}\")\n",
    "\n",
    "if final_missing == 0:\n",
    "    print(\"‚úÖ Data quality validation PASSED\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Data quality validation: Some issues remain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08e347af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ STEP 9: Save Cleaned Dataset\n",
      "----------------------------------------\n",
      "‚úÖ Cleaned dataset saved to: ../data/financial_data_cleaned.csv\n",
      "üìÅ File size: 0.12 MB\n",
      "‚úÖ Verification: Successfully loaded 700 records\n",
      "\n",
      "============================================================\n",
      "üéâ DATA CLEANING PROCESS COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "üìä Final Dataset Info:\n",
      "   ‚Ä¢ Records: 700\n",
      "   ‚Ä¢ Columns: 20\n",
      "   ‚Ä¢ Date Range: 2013-01-09 to 2014-01-12\n",
      "   ‚Ä¢ Total Sales: $118,726,350.29\n",
      "   ‚Ä¢ Total Profit: $17,671,023.54\n",
      "\n",
      "üìà Key KPIs Created:\n",
      "   ‚Ä¢ Discount_Band: 4 unique categories\n",
      "   ‚Ä¢ Units_Sold: 1608.29\n",
      "   ‚Ä¢ Manufacturing_Price: 96.48\n",
      "   ‚Ä¢ Sale_Price: 118.43\n",
      "   ‚Ä¢ Gross_Sales: 182759.43\n",
      "   ‚Ä¢ Month_Number: 7.90\n",
      "   ‚Ä¢ Month_Name: 12 unique categories\n",
      "   ‚Ä¢ Profit_Margin: 28.46\n",
      "   ‚Ä¢ Cost_Ratio: 72.10\n",
      "   ‚Ä¢ Revenue_per_Unit: 109.80\n",
      "   ‚Ä¢ Discount_Percentage: 7.33\n",
      "\n",
      "üìã Data Types Summary:\n",
      "   ‚Ä¢ Numeric columns: 13\n",
      "   ‚Ä¢ Categorical columns: 5\n",
      "   ‚Ä¢ Date columns: 1\n",
      "\n",
      "üéØ Next Step: Run '02_analysis_visuals.ipynb' for EDA!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîπ STEP 9: Save Cleaned Dataset\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 9.1 Save to CSV\n",
    "output_path = \"../data/financial_data_cleaned.csv\"\n",
    "\n",
    "try:\n",
    "    df_clean.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Cleaned dataset saved to: {output_path}\")\n",
    "    \n",
    "    # Verify file was created\n",
    "    file_size = os.path.getsize(output_path) / 1024 / 1024  # Size in MB\n",
    "    print(f\"üìÅ File size: {file_size:.2f} MB\")\n",
    "    \n",
    "    # Verify we can load it back\n",
    "    verify_df = pd.read_csv(output_path)\n",
    "    print(f\"‚úÖ Verification: Successfully loaded {len(verify_df)} records\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error saving dataset: {e}\")\n",
    "\n",
    "# 9.2 Final Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ DATA CLEANING PROCESS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"üìä Final Dataset Info:\")\n",
    "print(f\"   ‚Ä¢ Records: {len(df_clean)}\")\n",
    "print(f\"   ‚Ä¢ Columns: {len(df_clean.columns)}\")\n",
    "\n",
    "# Safe date range display\n",
    "try:\n",
    "    if 'Date' in df_clean.columns and pd.api.types.is_datetime64_any_dtype(df_clean['Date']):\n",
    "        date_min = df_clean['Date'].min()\n",
    "        date_max = df_clean['Date'].max()\n",
    "        print(f\"   ‚Ä¢ Date Range: {date_min.strftime('%Y-%m-%d')} to {date_max.strftime('%Y-%m-%d')}\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Date Range: Date column not available or not datetime\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚Ä¢ Date Range: Error displaying date range\")\n",
    "\n",
    "# Safe numeric calculations\n",
    "try:\n",
    "    if 'Sales' in df_clean.columns and pd.api.types.is_numeric_dtype(df_clean['Sales']):\n",
    "        total_sales = df_clean['Sales'].sum()\n",
    "        print(f\"   ‚Ä¢ Total Sales: ${total_sales:,.2f}\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Total Sales: Sales column not available or not numeric\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚Ä¢ Total Sales: Error calculating sales\")\n",
    "\n",
    "try:\n",
    "    if 'Profit' in df_clean.columns and pd.api.types.is_numeric_dtype(df_clean['Profit']):\n",
    "        total_profit = df_clean['Profit'].sum()\n",
    "        print(f\"   ‚Ä¢ Total Profit: ${total_profit:,.2f}\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Total Profit: Profit column not available or not numeric\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚Ä¢ Total Profit: Error calculating profit\")\n",
    "\n",
    "print(f\"\\nüìà Key KPIs Created:\")\n",
    "new_features = [col for col in df_clean.columns if col not in df.columns]\n",
    "\n",
    "for feature in new_features:\n",
    "    if feature in df_clean.columns:\n",
    "        try:\n",
    "            # Only calculate mean for numeric columns\n",
    "            if pd.api.types.is_numeric_dtype(df_clean[feature]):\n",
    "                avg_value = df_clean[feature].mean()\n",
    "                print(f\"   ‚Ä¢ {feature}: {avg_value:.2f}\")\n",
    "            else:\n",
    "                # For categorical columns, show value counts\n",
    "                unique_count = df_clean[feature].nunique()\n",
    "                print(f\"   ‚Ä¢ {feature}: {unique_count} unique categories\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚Ä¢ {feature}: Error calculating statistics\")\n",
    "\n",
    "# Additional: Show data types summary\n",
    "print(f\"\\nüìã Data Types Summary:\")\n",
    "print(f\"   ‚Ä¢ Numeric columns: {len(df_clean.select_dtypes(include=['int64', 'float64']).columns)}\")\n",
    "print(f\"   ‚Ä¢ Categorical columns: {len(df_clean.select_dtypes(include=['object', 'category']).columns)}\")\n",
    "print(f\"   ‚Ä¢ Date columns: {len(df_clean.select_dtypes(include=['datetime64']).columns)}\")\n",
    "\n",
    "print(f\"\\nüéØ Next Step: Run '02_analysis_visuals.ipynb' for EDA!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
